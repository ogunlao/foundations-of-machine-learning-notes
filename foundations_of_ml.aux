\relax 
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Supervised Learning}{3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Regression Problem}{3}\protected@file@percent }
\newlabel{data_table}{{1.1}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Table showing features and target of measurements gotten from observing tubers of yam sales. }}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Hypothesis}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Criteria}{4}\protected@file@percent }
\newlabel{loss_function}{{1.2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Learning Algorithm}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Numerical Approach}{4}\protected@file@percent }
\newlabel{gradient descent}{{1.3}{4}}
\@writefile{toc}{\contentsline {subsubsection}{Computing the Gradient of Loss Function}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Gradient Descent}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mini-batch Stochastic Gradient Descent}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Analytical Method}{6}\protected@file@percent }
\newlabel{normal_eqn}{{1.4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Newton Method showing theta update}}{7}\protected@file@percent }
\newlabel{fig:loss-landscape}{{1.1}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Newton's Method}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Maximum Likelihood Estimation}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Classification Problem}{8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces }}{9}\protected@file@percent }
\newlabel{fig:logistic-regression}{{1.2}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Hypothesis}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Logistic Regression}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Criteria}{9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Sigmoid}}{10}\protected@file@percent }
\newlabel{fig:sigmoid}{{1.3}{10}}
\newlabel{cross-entropy-loss}{{1.7}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Learning Algorithm}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Computing the Gradient}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Derivative of the sigmoid function}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Risk Minimization}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bias and Variance}{12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces }}{13}\protected@file@percent }
\newlabel{fig:biasvariance}{{1.4}{13}}
\@writefile{toc}{\contentsline {subsubsection}{K-Fold Cross Validation}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hints}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Reducing the Model Complexity}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection with Wrapper Methods}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection with Filter Methods}{15}\protected@file@percent }
