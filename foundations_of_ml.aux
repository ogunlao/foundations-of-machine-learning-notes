\relax 
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Supervised Learning}{3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Regression Problem}{3}\protected@file@percent }
\newlabel{data_table}{{1.1}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Table showing features and target of measurements gotten from observing tubers of yam sales. }}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Hypothesis}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Criteria}{5}\protected@file@percent }
\newlabel{loss_function}{{1.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Learning Algorithm}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Numerical Approach}{5}\protected@file@percent }
\newlabel{gradient descent}{{1.3}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Computing the Gradient of Loss Function}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Gradient Descent}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mini-batch Stochastic Gradient Descent}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Analytical Method}{7}\protected@file@percent }
\newlabel{normal_eqn}{{1.4}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Newton's Method}{8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Newton Method showing theta update}}{9}\protected@file@percent }
\newlabel{fig:loss-landscape}{{1.1}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Maximum Likelihood Estimation}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Classification Problem}{11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces }}{12}\protected@file@percent }
\newlabel{fig:logistic-regression}{{1.2}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Hypothesis}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Logistic Regression}{12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Sigmoid}}{13}\protected@file@percent }
\newlabel{fig:sigmoid}{{1.3}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Criteria}{13}\protected@file@percent }
\newlabel{cross-entropy-loss}{{1.7}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Learning Algorithm}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Computing the Gradient}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Derivative of the sigmoid function}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Risk Minimization}{15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces }}{17}\protected@file@percent }
\newlabel{fig:biasvariance}{{1.4}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Bias and Variance}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{K-Fold Cross Validation}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hints}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Reducing the Model Complexity}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection with Wrapper Methods}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection with Filter Methods}{20}\protected@file@percent }
