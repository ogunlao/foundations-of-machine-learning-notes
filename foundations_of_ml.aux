\relax 
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Supervised Learning}{4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Regression Problem}{4}\protected@file@percent }
\newlabel{data_table}{{1.1}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Table showing features and target of measurements gotten from observing tubers of yam sales. }}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Hypothesis}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Criteria}{5}\protected@file@percent }
\newlabel{loss_function}{{1.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Learning Algorithm}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Numerical Approach}{5}\protected@file@percent }
\newlabel{gradient descent}{{1.3}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Computing the Gradient of Loss Function}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Gradient Descent}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Mini-batch Stochastic Gradient Descent}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Analytical Method}{7}\protected@file@percent }
\newlabel{normal_eqn}{{1.4}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Newton Method showing theta update}}{8}\protected@file@percent }
\newlabel{fig:loss-landscape}{{1.1}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Newton's Method}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Maximum Likelihood Estimation}{9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces }}{10}\protected@file@percent }
\newlabel{fig:logistic-regression}{{1.2}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Classification Problem}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Hypothesis}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Logistic Regression}{10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Sigmoid}}{11}\protected@file@percent }
\newlabel{fig:sigmoid}{{1.3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Criteria}{11}\protected@file@percent }
\newlabel{cross-entropy-loss}{{1.7}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Learning Algorithm}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Computing the Gradient}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Derivative of the sigmoid function}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Risk Minimization}{13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces }}{14}\protected@file@percent }
\newlabel{fig:biasvariance}{{1.4}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Bias and Variance}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}K-Fold Cross Validation}{14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Hints}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Reducing the Model Complexity}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection with Wrapper Methods}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Feature Selection with Filter Methods}{16}\protected@file@percent }
